{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 14.9\n",
    "## Hands-on Machine Learning with Scikit-Learn, Keras and Tensorflow, 2nd Ed\n",
    "\n",
    "__Andrés Felipe García Albarracín <br>\n",
    "Feb 8, 2021__ <br>\n",
    "\n",
    "Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices(device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitad = int(x_test.shape[0]/2)\n",
    "x_val = x_test[0:mitad,:,:]\n",
    "x_test = x_test[mitad:,:,:]\n",
    "y_val = y_test[0:mitad]\n",
    "y_test = y_test[mitad:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "x_test.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colResults = [\"Model_name\", \"Description\", \"Loss\", \"Accuracy\"]\n",
    "dfResults = pd.DataFrame(columns=colResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) A model very similar to LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 14, 14, 8)         208       \n_________________________________________________________________\naverage_pooling2d (AveragePo (None, 7, 7, 8)           0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 7, 7, 16)          1168      \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, 3, 3, 16)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 3, 3, 64)          4160      \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 1, 1, 128)         73856     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 1, 1, 32)          4128      \n_________________________________________________________________\nflatten (Flatten)            (None, 32)                0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                330       \n=================================================================\nTotal params: 83,850\nTrainable params: 83,850\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.7541 - accuracy: 0.1250WARNING:tensorflow:From /home/data/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1875 [..............................] - ETA: 3:54 - loss: 3.9040 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0512s vs `on_train_batch_end` time: 0.1987s). Check your callbacks.\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2433 - accuracy: 0.9216 - val_loss: 0.1154 - val_accuracy: 0.9654\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0912 - accuracy: 0.9723 - val_loss: 0.1080 - val_accuracy: 0.9678\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0762 - accuracy: 0.9778 - val_loss: 0.1080 - val_accuracy: 0.9732\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0718 - accuracy: 0.9810 - val_loss: 0.0889 - val_accuracy: 0.9758\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.0785 - val_accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0714 - accuracy: 0.9811 - val_loss: 0.1128 - val_accuracy: 0.9718\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0736 - accuracy: 0.9819 - val_loss: 0.0904 - val_accuracy: 0.9774\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0755 - accuracy: 0.9819 - val_loss: 0.0956 - val_accuracy: 0.9776\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9819 - val_loss: 0.1399 - val_accuracy: 0.9618\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0881 - accuracy: 0.9808 - val_loss: 0.1716 - val_accuracy: 0.9672\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9803 - val_loss: 0.1012 - val_accuracy: 0.9758\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0845 - accuracy: 0.9803 - val_loss: 0.1241 - val_accuracy: 0.9774\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0951 - accuracy: 0.9795 - val_loss: 0.1818 - val_accuracy: 0.9670\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9800 - val_loss: 0.2101 - val_accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1015 - accuracy: 0.9785 - val_loss: 0.1347 - val_accuracy: 0.9738\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0470027280>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(\"model_A_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9898\n",
      "[0.04155489057302475, 0.989799976348877]\n"
     ]
    }
   ],
   "source": [
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name       Description      Loss  Accuracy\n",
       "0          A  Similar to LeNet  0.041555    0.9898"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "resultAct.insert(0,'A')\n",
    "resultAct.insert(1,'Similar to LeNet')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Similar to LeNet and incluiding dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.45)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 14, 14, 8)         208       \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, 7, 7, 8)           0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 7, 7, 16)          1168      \n_________________________________________________________________\naverage_pooling2d_3 (Average (None, 3, 3, 16)          0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 3, 3, 64)          4160      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 1, 1, 128)         73856     \n_________________________________________________________________\ndropout (Dropout)            (None, 1, 1, 128)         0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 1, 1, 32)          4128      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1, 1, 32)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 83,850\nTrainable params: 83,850\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   2/1875 [..............................] - ETA: 1:24 - loss: 6.1584 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0757s). Check your callbacks.\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5856 - accuracy: 0.8201 - val_loss: 0.2255 - val_accuracy: 0.9458\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.9393 - val_loss: 0.1802 - val_accuracy: 0.9544\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2706 - accuracy: 0.9431 - val_loss: 0.2664 - val_accuracy: 0.9488\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2917 - accuracy: 0.9408 - val_loss: 0.2352 - val_accuracy: 0.9508\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3185 - accuracy: 0.9365 - val_loss: 0.2265 - val_accuracy: 0.9624\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3281 - accuracy: 0.9366 - val_loss: 0.3525 - val_accuracy: 0.9430\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3628 - accuracy: 0.9316 - val_loss: 0.2243 - val_accuracy: 0.9444\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3580 - accuracy: 0.9318 - val_loss: 0.2112 - val_accuracy: 0.9562\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3712 - accuracy: 0.9275 - val_loss: 0.2707 - val_accuracy: 0.9532\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3912 - accuracy: 0.9264 - val_loss: 0.2504 - val_accuracy: 0.9468\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4146 - accuracy: 0.9240 - val_loss: 0.5677 - val_accuracy: 0.9226\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4235 - accuracy: 0.9222 - val_loss: 0.2654 - val_accuracy: 0.9392\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04f8516dc0>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# =========================\n",
    "# Compile model\n",
    "# =========================\n",
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])\n",
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(\"model_B_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1366 - accuracy: 0.9668\n",
      "[0.13664942979812622, 0.966783344745636]\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.9544\n",
      "[0.18021848797798157, 0.9544000029563904]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x = x_train, y = y_train))\n",
    "print(model.evaluate(x = x_val, y = y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0896 - accuracy: 0.9782\n",
      "[0.08964071422815323, 0.9782000184059143]\n"
     ]
    }
   ],
   "source": [
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name                                        Description      Loss  \\\n",
       "0          A                                   Similar to LeNet  0.041555   \n",
       "1          B  Similar to LeNet including dropout at the fina...  0.089641   \n",
       "\n",
       "   Accuracy  \n",
       "0    0.9898  \n",
       "1    0.9782  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B</td>\n      <td>Similar to LeNet including dropout at the fina...</td>\n      <td>0.089641</td>\n      <td>0.9782</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "resultAct.insert(0,'B')\n",
    "resultAct.insert(1,'Similar to LeNet including dropout at the final layers')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Local response normalization\n",
    "Including some local response normalization layers at the beggining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 14, 14, 8)         208       \n_________________________________________________________________\naverage_pooling2d_4 (Average (None, 7, 7, 8)           0         \n_________________________________________________________________\nlambda (Lambda)              (None, 7, 7, 8)           0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 7, 7, 16)          1168      \n_________________________________________________________________\naverage_pooling2d_5 (Average (None, 3, 3, 16)          0         \n_________________________________________________________________\nlambda_1 (Lambda)            (None, 3, 3, 16)          0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 3, 3, 64)          4160      \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 1, 1, 128)         73856     \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 1, 1, 32)          4128      \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 83,850\nTrainable params: 83,850\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   2/1875 [..............................] - ETA: 1:28 - loss: 4.8425 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0112s vs `on_train_batch_end` time: 0.0815s). Check your callbacks.\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2536 - accuracy: 0.9196 - val_loss: 0.1389 - val_accuracy: 0.9592\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9723 - val_loss: 0.1618 - val_accuracy: 0.9526\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.0937 - val_accuracy: 0.9748\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9794 - val_loss: 0.1895 - val_accuracy: 0.9610\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9805 - val_loss: 0.1369 - val_accuracy: 0.9684\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0790 - accuracy: 0.9807 - val_loss: 0.1031 - val_accuracy: 0.9714\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9805 - val_loss: 0.1581 - val_accuracy: 0.9646\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0834 - accuracy: 0.9801 - val_loss: 0.1021 - val_accuracy: 0.9738\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9796 - val_loss: 0.1080 - val_accuracy: 0.9754\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0844 - accuracy: 0.9802 - val_loss: 0.0960 - val_accuracy: 0.9766\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0857 - accuracy: 0.9804 - val_loss: 0.1609 - val_accuracy: 0.9720\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9793 - val_loss: 0.0999 - val_accuracy: 0.9744\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0875 - accuracy: 0.9808 - val_loss: 0.1780 - val_accuracy: 0.9628\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f046052bac0>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# =========================\n",
    "# Compile model\n",
    "# =========================\n",
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])\n",
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(\"model_C_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0566 - accuracy: 0.9838\n",
      "[0.056593604385852814, 0.9837666749954224]\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9748\n",
      "[0.09369237720966339, 0.9747999906539917]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x = x_train, y = y_train))\n",
    "print(model.evaluate(x = x_val, y = y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9876\n",
      "[0.037427883595228195, 0.9876000285148621]\n"
     ]
    }
   ],
   "source": [
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name                                        Description      Loss  \\\n",
       "0          A                                   Similar to LeNet  0.041555   \n",
       "1          B  Similar to LeNet including dropout at the fina...  0.089641   \n",
       "2          C  Including local responde normalization in the ...  0.037428   \n",
       "\n",
       "   Accuracy  \n",
       "0    0.9898  \n",
       "1    0.9782  \n",
       "2    0.9876  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B</td>\n      <td>Similar to LeNet including dropout at the fina...</td>\n      <td>0.089641</td>\n      <td>0.9782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C</td>\n      <td>Including local responde normalization in the ...</td>\n      <td>0.037428</td>\n      <td>0.9876</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "resultAct.insert(0,'C')\n",
    "resultAct.insert(1,'Including local responde normalization in the initial layers.')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Going deeper\n",
    "Including more convolutional layers with local response normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 14, 14, 8)         208       \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 14, 14, 16)        3216      \n_________________________________________________________________\naverage_pooling2d_6 (Average (None, 7, 7, 16)          0         \n_________________________________________________________________\nlambda_2 (Lambda)            (None, 7, 7, 16)          0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 7, 7, 32)          4640      \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 7, 7, 32)          9248      \n_________________________________________________________________\naverage_pooling2d_7 (Average (None, 3, 3, 32)          0         \n_________________________________________________________________\nlambda_3 (Lambda)            (None, 3, 3, 32)          0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 3, 3, 64)          8256      \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 3, 3, 64)          16448     \n_________________________________________________________________\nconv2d_21 (Conv2D)           (None, 1, 1, 128)         73856     \n_________________________________________________________________\nconv2d_22 (Conv2D)           (None, 1, 1, 32)          4128      \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 120,330\nTrainable params: 120,330\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "modelName = 'D'\n",
    "\n",
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "   2/1875 [..............................] - ETA: 1:18 - loss: 2.4135 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0787s). Check your callbacks.\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2153 - accuracy: 0.9331 - val_loss: 0.1244 - val_accuracy: 0.9608\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0765 - accuracy: 0.9786 - val_loss: 0.0917 - val_accuracy: 0.9762\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0679 - accuracy: 0.9821 - val_loss: 0.0789 - val_accuracy: 0.9776\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0689 - accuracy: 0.9834 - val_loss: 0.0876 - val_accuracy: 0.9740\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0676 - accuracy: 0.9837 - val_loss: 0.1095 - val_accuracy: 0.9764\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9842 - val_loss: 0.0866 - val_accuracy: 0.9786\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0728 - accuracy: 0.9841 - val_loss: 0.1225 - val_accuracy: 0.9670\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0805 - accuracy: 0.9840 - val_loss: 0.2177 - val_accuracy: 0.9652\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0810 - accuracy: 0.9830 - val_loss: 0.0907 - val_accuracy: 0.9716\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0944 - accuracy: 0.9818 - val_loss: 0.1145 - val_accuracy: 0.9748\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0934 - accuracy: 0.9814 - val_loss: 0.1182 - val_accuracy: 0.9730\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1177 - accuracy: 0.9806 - val_loss: 0.3326 - val_accuracy: 0.9724\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1112 - accuracy: 0.9802 - val_loss: 0.3805 - val_accuracy: 0.9644\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04603f1c10>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# =========================\n",
    "# Compile model\n",
    "# =========================\n",
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])\n",
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(f\"model_{modelName}_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0532 - accuracy: 0.9850\n",
      "[0.05319029465317726, 0.9850000143051147]\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9776\n",
      "[0.07887808233499527, 0.9775999784469604]\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9914\n",
      "[0.0319429486989975, 0.9914000034332275]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x = x_train, y = y_train))\n",
    "print(model.evaluate(x = x_val, y = y_val))\n",
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name                                        Description      Loss  \\\n",
       "0          A                                   Similar to LeNet  0.041555   \n",
       "1          B  Similar to LeNet including dropout at the fina...  0.089641   \n",
       "2          C  Including local responde normalization in the ...  0.037428   \n",
       "3          D   Including more layers in the LeNet architecture.  0.031943   \n",
       "\n",
       "   Accuracy  \n",
       "0    0.9898  \n",
       "1    0.9782  \n",
       "2    0.9876  \n",
       "3    0.9914  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B</td>\n      <td>Similar to LeNet including dropout at the fina...</td>\n      <td>0.089641</td>\n      <td>0.9782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C</td>\n      <td>Including local responde normalization in the ...</td>\n      <td>0.037428</td>\n      <td>0.9876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>Including more layers in the LeNet architecture.</td>\n      <td>0.031943</td>\n      <td>0.9914</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "resultAct.insert(0,modelName)\n",
    "resultAct.insert(1,'Including more layers in the LeNet architecture.')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Including inception blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inceptionLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Creates an inception layer following thar architecture of Google Net\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_filters = [8, 16, 4, 4, 12, 2], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = [\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[0], kernel_size = 1, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[1], kernel_size = 3, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[2], kernel_size = 5, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[3], kernel_size = 1, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[4], kernel_size = 1, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.Conv2D(filters = layer_filters[5], kernel_size = 1, strides = 1, padding = \"same\", activation = \"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size = 3, strides = 1, padding = \"same\")\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        path0 = self.layers[0](inputs)\n",
    "\n",
    "        path1 = self.layers[4](inputs)\n",
    "        path1 = self.layers[1](path1)\n",
    "\n",
    "        path2 = self.layers[5](inputs)\n",
    "        path2 = self.layers[2](path2)\n",
    "\n",
    "        path3 = self.layers[6](inputs)\n",
    "        path3 = self.layers[3](path3)\n",
    "\n",
    "        final = tf.concat([path0, path1, path2, path3], axis = 3)\n",
    "\n",
    "        return final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_11\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_41 (Conv2D)           (None, 14, 14, 8)         208       \n_________________________________________________________________\nconv2d_42 (Conv2D)           (None, 14, 14, 16)        3216      \n_________________________________________________________________\naverage_pooling2d_10 (Averag (None, 7, 7, 16)          0         \n_________________________________________________________________\nlambda_6 (Lambda)            (None, 7, 7, 16)          0         \n_________________________________________________________________\ninception_layer_2 (inception (None, 7, 7, 32)          2390      \n_________________________________________________________________\ninception_layer_3 (inception (None, 7, 7, 64)          9468      \n_________________________________________________________________\naverage_pooling2d_11 (Averag (None, 3, 3, 64)          0         \n_________________________________________________________________\nlambda_7 (Lambda)            (None, 3, 3, 64)          0         \n_________________________________________________________________\nconv2d_55 (Conv2D)           (None, 3, 3, 64)          16448     \n_________________________________________________________________\nconv2d_56 (Conv2D)           (None, 3, 3, 64)          16448     \n_________________________________________________________________\nconv2d_57 (Conv2D)           (None, 1, 1, 128)         73856     \n_________________________________________________________________\nconv2d_58 (Conv2D)           (None, 1, 1, 32)          4128      \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                330       \n=================================================================\nTotal params: 126,492\nTrainable params: 126,492\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "modelName = 'E'\n",
    "\n",
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = inceptionLayer(layer_filters = [8, 16, 4, 4, 12, 2])(x)\n",
    "x = inceptionLayer(layer_filters = [16, 32, 8, 8, 24, 4])(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = 2, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer inceptionLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/100\n",
      "   2/1875 [..............................] - ETA: 2:17 - loss: 3.0421 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.1393s). Check your callbacks.\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2519 - accuracy: 0.9201 - val_loss: 0.2122 - val_accuracy: 0.9356\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0960 - accuracy: 0.9738 - val_loss: 0.0889 - val_accuracy: 0.9746\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0884 - accuracy: 0.9772 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0863 - accuracy: 0.9779 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0882 - accuracy: 0.9782 - val_loss: 0.1428 - val_accuracy: 0.9660\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1325 - accuracy: 0.9779 - val_loss: 0.0977 - val_accuracy: 0.9760\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1007 - accuracy: 0.9780 - val_loss: 0.2983 - val_accuracy: 0.9504\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1066 - accuracy: 0.9765 - val_loss: 0.0972 - val_accuracy: 0.9698\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1086 - accuracy: 0.9763 - val_loss: 0.1716 - val_accuracy: 0.9776\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1146 - accuracy: 0.9756 - val_loss: 0.1316 - val_accuracy: 0.9634\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1147 - accuracy: 0.9747 - val_loss: 0.1839 - val_accuracy: 0.9566\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1371 - accuracy: 0.9749 - val_loss: 0.1255 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03e079df10>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# =========================\n",
    "# Compile model\n",
    "# =========================\n",
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])\n",
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(f\"model_{modelName}_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0620 - accuracy: 0.9822\n",
      "[0.061971139162778854, 0.9821666479110718]\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9746\n",
      "[0.08886697888374329, 0.9746000170707703]\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9894\n",
      "[0.038159020245075226, 0.9894000291824341]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x = x_train, y = y_train))\n",
    "print(model.evaluate(x = x_val, y = y_val))\n",
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name                                        Description      Loss  \\\n",
       "0          A                                   Similar to LeNet  0.041555   \n",
       "1          B  Similar to LeNet including dropout at the fina...  0.089641   \n",
       "2          C  Including local responde normalization in the ...  0.037428   \n",
       "3          D   Including more layers in the LeNet architecture.  0.031943   \n",
       "4          E   Including more layers in the LeNet architecture.  0.038159   \n",
       "\n",
       "   Accuracy  \n",
       "0    0.9898  \n",
       "1    0.9782  \n",
       "2    0.9876  \n",
       "3    0.9914  \n",
       "4    0.9894  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B</td>\n      <td>Similar to LeNet including dropout at the fina...</td>\n      <td>0.089641</td>\n      <td>0.9782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C</td>\n      <td>Including local responde normalization in the ...</td>\n      <td>0.037428</td>\n      <td>0.9876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>Including more layers in the LeNet architecture.</td>\n      <td>0.031943</td>\n      <td>0.9914</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E</td>\n      <td>Including more layers in the LeNet architecture.</td>\n      <td>0.038159</td>\n      <td>0.9894</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "resultAct.insert(0,modelName)\n",
    "resultAct.insert(1,'Including inception layers')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  },
  {
   "source": [
    "### f) Making the Inception architecture even deeper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n_________________________________________________________________\nconv2d_113 (Conv2D)          (None, 14, 14, 8)         208       \n_________________________________________________________________\nconv2d_114 (Conv2D)          (None, 14, 14, 16)        3216      \n_________________________________________________________________\naverage_pooling2d_14 (Averag (None, 7, 7, 16)          0         \n_________________________________________________________________\nlambda_10 (Lambda)           (None, 7, 7, 16)          0         \n_________________________________________________________________\ninception_layer_12 (inceptio (None, 7, 7, 32)          2390      \n_________________________________________________________________\ninception_layer_13 (inceptio (None, 7, 7, 64)          9468      \n_________________________________________________________________\nmax_pooling2d_16 (MaxPooling (None, 3, 3, 64)          0         \n_________________________________________________________________\ninception_layer_14 (inceptio (None, 3, 3, 128)         37688     \n_________________________________________________________________\ninception_layer_15 (inceptio (None, 3, 3, 256)         150384    \n_________________________________________________________________\nconv2d_139 (Conv2D)          (None, 3, 3, 128)         32896     \n_________________________________________________________________\nconv2d_140 (Conv2D)          (None, 3, 3, 32)          4128      \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 288)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 10)                2890      \n=================================================================\nTotal params: 243,268\nTrainable params: 243,268\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "modelName = 'F'\n",
    "\n",
    "inputs = tf.keras.Input(shape = (28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters = 8, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"same\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.AveragePooling2D(pool_size = 2, strides = 2, padding = \"valid\")(x)\n",
    "x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = inceptionLayer(layer_filters = [8, 16, 4, 4, 12, 2])(x)\n",
    "x = inceptionLayer(layer_filters = [16, 32, 8, 8, 24, 4])(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size = 3, strides = 2, padding = \"valid\")(x)\n",
    "#x = tf.keras.layers.Lambda(lambda x: tf.nn.local_response_normalization(x, depth_radius=2, bias=1, alpha=0.00002, beta=0.75))(x)\n",
    "x = inceptionLayer(layer_filters = [32, 64, 16, 16, 48, 8])(x)\n",
    "x = inceptionLayer(layer_filters = [64, 128, 32, 32, 96, 16])(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = 1, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(units = 10, activation = \"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer inceptionLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/100\n",
      "   2/1875 [..............................] - ETA: 3:19 - loss: 7.1363 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0103s vs `on_train_batch_end` time: 0.2020s). Check your callbacks.\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2821 - accuracy: 0.9123 - val_loss: 0.1215 - val_accuracy: 0.9640\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0959 - accuracy: 0.9721 - val_loss: 0.0962 - val_accuracy: 0.9716\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0825 - accuracy: 0.9780 - val_loss: 0.1297 - val_accuracy: 0.9642\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0812 - accuracy: 0.9791 - val_loss: 0.1187 - val_accuracy: 0.9678\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0888 - accuracy: 0.9804 - val_loss: 0.1285 - val_accuracy: 0.9752\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0788 - accuracy: 0.9809 - val_loss: 0.1073 - val_accuracy: 0.9704\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0750 - accuracy: 0.9812 - val_loss: 0.0940 - val_accuracy: 0.9732\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0768 - accuracy: 0.9826 - val_loss: 0.0895 - val_accuracy: 0.9780\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0921 - accuracy: 0.9832 - val_loss: 0.1300 - val_accuracy: 0.9666\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0821 - accuracy: 0.9829 - val_loss: 0.0922 - val_accuracy: 0.9780\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.0546 - accuracy: 0.9841 - val_loss: 0.0964 - val_accuracy: 0.9824\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.6670 - accuracy: 0.9835 - val_loss: 0.1138 - val_accuracy: 0.9750\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2504 - accuracy: 0.9850 - val_loss: 0.1124 - val_accuracy: 0.9746\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0674 - accuracy: 0.9847 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2517 - accuracy: 0.9853 - val_loss: 0.0758 - val_accuracy: 0.9782\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0659 - accuracy: 0.9855 - val_loss: 0.1164 - val_accuracy: 0.9774\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1819 - accuracy: 0.9852 - val_loss: 0.0614 - val_accuracy: 0.9828\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1258 - accuracy: 0.9847 - val_loss: 0.0715 - val_accuracy: 0.9782\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0633 - accuracy: 0.9852 - val_loss: 0.0608 - val_accuracy: 0.9812\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.3533 - accuracy: 0.9858 - val_loss: 0.2219 - val_accuracy: 0.9798\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0704 - accuracy: 0.9850 - val_loss: 0.1685 - val_accuracy: 0.9822\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1801 - accuracy: 0.9846 - val_loss: 0.0719 - val_accuracy: 0.9810\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.0879 - accuracy: 0.9808 - val_loss: 0.0844 - val_accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4169 - accuracy: 0.9833 - val_loss: 0.2623 - val_accuracy: 0.9392\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 11.9451 - accuracy: 0.9818 - val_loss: 0.0992 - val_accuracy: 0.9764\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.4869 - accuracy: 0.9845 - val_loss: 0.1248 - val_accuracy: 0.9714\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0962 - accuracy: 0.9833 - val_loss: 0.2138 - val_accuracy: 0.9676\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.4339 - accuracy: 0.9752 - val_loss: 0.1036 - val_accuracy: 0.9806\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2323 - accuracy: 0.9818 - val_loss: 0.1041 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f03e056ba00>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# =========================\n",
    "# Compile model\n",
    "# =========================\n",
    "model.compile(\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = ['accuracy'])\n",
    "# =========================\n",
    "# Training Parameters\n",
    "# =========================\n",
    "epochs = 100\n",
    "patience = 10\n",
    "# =========================\n",
    "# Callbacks\n",
    "# =========================\n",
    "tb_cb = tf.keras.callbacks.TensorBoard(\"./Results_tensorboard/Ex_14_9/\" + time.strftime(f\"model_{modelName}_%Y_%m_%d_%H_%M_%S\"))\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(patience= patience, restore_best_weights=True)\n",
    "# =========================\n",
    "# Training\n",
    "# =========================\n",
    "model.fit(\n",
    "    x= x_train,\n",
    "    y= y_train,\n",
    "    epochs= epochs,\n",
    "    callbacks= [tb_cb, es_cb],\n",
    "    validation_data= (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0344 - accuracy: 0.9902\n",
      "[0.03438741713762283, 0.9902333617210388]\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9812\n",
      "[0.06078333035111427, 0.9811999797821045]\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9932\n",
      "[0.02412254922091961, 0.9932000041007996]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x = x_train, y = y_train))\n",
    "print(model.evaluate(x = x_val, y = y_val))\n",
    "resultAct = model.evaluate(x = x_test, y = y_test)\n",
    "print(resultAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Model_name                                        Description      Loss  \\\n",
       "0          A                                   Similar to LeNet  0.041555   \n",
       "1          B  Similar to LeNet including dropout at the fina...  0.089641   \n",
       "2          C  Including local responde normalization in the ...  0.037428   \n",
       "3          D   Including more layers in the LeNet architecture.  0.031943   \n",
       "4          E                         Including inception layers  0.038159   \n",
       "5          F            Making the inception layers even deeper  0.024123   \n",
       "\n",
       "   Accuracy  \n",
       "0    0.9898  \n",
       "1    0.9782  \n",
       "2    0.9876  \n",
       "3    0.9914  \n",
       "4    0.9894  \n",
       "5    0.9932  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Description</th>\n      <th>Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A</td>\n      <td>Similar to LeNet</td>\n      <td>0.041555</td>\n      <td>0.9898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B</td>\n      <td>Similar to LeNet including dropout at the fina...</td>\n      <td>0.089641</td>\n      <td>0.9782</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C</td>\n      <td>Including local responde normalization in the ...</td>\n      <td>0.037428</td>\n      <td>0.9876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>D</td>\n      <td>Including more layers in the LeNet architecture.</td>\n      <td>0.031943</td>\n      <td>0.9914</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E</td>\n      <td>Including inception layers</td>\n      <td>0.038159</td>\n      <td>0.9894</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>F</td>\n      <td>Making the inception layers even deeper</td>\n      <td>0.024123</td>\n      <td>0.9932</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "resultAct.insert(0,modelName)\n",
    "resultAct.insert(1,'Making the inception layers even deeper')\n",
    "dfResults = dfResults.append(\n",
    "    pd.DataFrame(columns = colResults, data=[resultAct]),\n",
    "    ignore_index=True)\n",
    "dfResults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Estudio env)",
   "language": "python",
   "name": "estudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}